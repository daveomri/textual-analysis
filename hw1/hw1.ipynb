{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Omrai\n",
    "20.3.2022\n",
    "\n",
    "Data a parametry\n",
    "Každý z datových souborů reprezentuje prvních cca 1000 slov nějaké anglické knihy.\n",
    "\n",
    "!  V prvním řádku se vždy nachází informace o knize a autorovi  (tanto řádek pro analýzu ignorujte).\n",
    "\n",
    "! V některých textech se nevyskytují všechny znaky anglické abecedy. To může být pro některé úlohy problém a je třeba se k němu postavit čelem! Může pomoct prohození souborů (tj. označení první a druhy), nebo přidání nevyskytujícího se znaku s nulovou pravděpodobností.\n",
    "\n",
    "\n",
    "Zadání úlohy\n",
    "1) Z obou datových souborů načtěte texty k analýze. Pro každý text zvlášť odhadněte pravděpodobnosti znaků (symbolů všetně mezery), které se v textech vyskytují. Výsledné pravděpodobnosti graficky znázorněte. \n",
    "2) Pro každý text zvlášť spočtěte entropii odhadnutého rozdělení znaků.\n",
    "3) Nalezněte optimální binární instantní kód C pro kódování znaků prvního z textů.\n",
    "4) Pro každý text zvlášť spočtěte střední délku kódu C a porovnejte ji s entropií rozdělení znaků. Je kód C optimální i pro druhý text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import scipy\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load proper data file\n",
    "# day of birth\n",
    "K = 9\n",
    "# last name length\n",
    "L = len(\"Omrai\")\n",
    "X = ((K*L*23) % (20)) + 1\n",
    "Y  = ((X + ((K*5 + L*7) % (19))) % (20)) + 1\n",
    "\n",
    "file_name_x = f\"{X:0=3d}.txt\"\n",
    "file_name_y = f\"{Y:0=3d}.txt\"\n",
    "file_loc = \"../hw1-source\"\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "file_x = read_file(\"{}/{}\".format(file_loc, file_name_x))\n",
    "file_y = read_file(\"{}/{}\".format(file_loc, file_name_y))\n",
    "\n",
    "data_x = {}\n",
    "data_y = {}\n",
    "\n",
    "data_x[\"name\"] = file_x.partition('\\n')[0]\n",
    "data_x[\"text\"] = file_x[len(data_x[\"name\"])+1:].strip().replace('\\n', ' ')\n",
    "\n",
    "data_y[\"name\"] = file_y.partition('\\n')[0]\n",
    "data_y[\"text\"] = file_y[len(data_y[\"name\"])+1:].strip().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# get just unique characters from texts\n",
    "# uniq_chars_x = ''.join(set(data_x[\"text\"]))\n",
    "# uniq_chars_y = ''.join(set(data_y[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the characters occurrence\n",
    "def count_characters(text):\n",
    "    chars_num = {}\n",
    "    for i in text:\n",
    "        if i not in chars_num.keys():\n",
    "            chars_num[i] = {}\n",
    "            chars_num[i][\"num\"] = 1\n",
    "        else:\n",
    "            chars_num[i][\"num\"] += 1\n",
    "\n",
    "    text_len = len(text)\n",
    "    for i in chars_num.keys():\n",
    "        chars_num[i][\"prob\"] = chars_num[i][\"num\"] / text_len\n",
    "\n",
    "    return chars_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_num_x = count_characters(data_x[\"text\"])\n",
    "uniq_num_y = count_characters(data_y[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t', 'h', 'e', ' ', 'r', 'p', 'u', 'b', 'l', 'i', 'c', 's', 'o', 'n', 'f', 'd', 'a', 'g', 'w', 'm', 'y', 'k', 'v', 'q', 'j', 'x'])\n",
      "dict_keys(['t', 'h', 'e', ' ', 'c', 'i', 'l', 'd', 'r', 'n', 'a', 'm', 'p', 'o', 'f', 's', 'u', 'g', 'b', 'y', 'w', 'v', 'k', 'q', 'j', 'x', 'z'])\n"
     ]
    }
   ],
   "source": [
    "print(uniq_num_x.keys())\n",
    "print(uniq_num_y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the rest of english characters\n",
    "eng_chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "def add_missing_chars(chars, uniq_dict):\n",
    "    for char in chars:\n",
    "        if (char not in uniq_dict.keys()):\n",
    "            uniq_dict[char] = {}\n",
    "            uniq_dict[char][\"num\"] = 0\n",
    "            uniq_dict[char][\"prob\"] = 0.0\n",
    "\n",
    "add_missing_chars(eng_chars, uniq_num_x)\n",
    "add_missing_chars(eng_chars, uniq_num_y)\n",
    "\n",
    "add_missing_chars(uniq_num_x.keys(), uniq_num_y)\n",
    "add_missing_chars(uniq_num_y.keys(), uniq_num_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': {'num': 453, 'prob': 0.07127123977344242}, 'h': {'num': 344, 'prob': 0.054122089364380115}, 'e': {'num': 638, 'prob': 0.10037759597230964}, ' ': {'num': 1249, 'prob': 0.19650723725613595}, 'r': {'num': 284, 'prob': 0.0446821900566394}, 'p': {'num': 91, 'prob': 0.014317180616740088}, 'u': {'num': 189, 'prob': 0.02973568281938326}, 'b': {'num': 58, 'prob': 0.009125235997482694}, 'l': {'num': 192, 'prob': 0.030207677784770296}, 'i': {'num': 321, 'prob': 0.05050346129641284}, 'c': {'num': 151, 'prob': 0.023757079924480805}, 's': {'num': 331, 'prob': 0.05207677784770296}, 'o': {'num': 427, 'prob': 0.0671806167400881}, 'n': {'num': 310, 'prob': 0.048772813089993705}, 'f': {'num': 100, 'prob': 0.015733165512901194}, 'd': {'num': 205, 'prob': 0.03225298930144745}, 'a': {'num': 455, 'prob': 0.07158590308370044}, 'g': {'num': 91, 'prob': 0.014317180616740088}, 'w': {'num': 132, 'prob': 0.02076777847702958}, 'm': {'num': 135, 'prob': 0.021239773442416614}, 'y': {'num': 131, 'prob': 0.020610446821900566}, 'k': {'num': 21, 'prob': 0.003303964757709251}, 'v': {'num': 36, 'prob': 0.005663939584644431}, 'q': {'num': 8, 'prob': 0.0012586532410320957}, 'j': {'num': 2, 'prob': 0.00031466331025802394}, 'x': {'num': 2, 'prob': 0.00031466331025802394}, 'z': {'num': 0, 'prob': 0.0}}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
